
> 前面我们实现了[Java爬虫爬取小百合BBS]()的单机版本，现在我们将其改造成mapreduce版本

<!-- more -->

# 前言
之前的文章我们爬取小百合所有板块的1000个帖子，然而数据量实在太大,小百合又有不能连续获取的限制，要全部爬完花费的时间过长(458*1000*0.5)。因此
我们决定爬取top20的板块，而每个板块的帖子上升到5000。为了利用Hadoop分布式的优势（完成实验任务),下面我们将其改造成Mapreduce版本。
没有安装Hadoop环境的可以参考[这篇文章]()

# 分析过程及代码
## 输入文件准备
共有20个热门板块，那么创建20个文本文件，每个文本文件中放一个板块的url。

## 爬取过程
爬取过程如下:
- Map过程: MapReduce程序读取输入文件中的url,作为一个map任务进行帖子爬取,将爬取到的每一条帖子输出
- Reduce过程：将得到的帖子原样输出

## 不足
这里map过程应该拿到一个帖子就输出的，而我是拿到该板块所有帖子再输出。==不过人懒，混实验罢了。
